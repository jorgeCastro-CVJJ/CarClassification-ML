## Clasificaci√≥n de Im√°genes de Carros Usando CNN
## üöó Clasificaci√≥n de Im√°genes de Carros
Este proyecto se enfoca en el desarrollo de un modelo de aprendizaje autom√°tico capaz de clasificar im√°genes de diferentes marcas de carros utilizando Redes Neuronales Convolucionales (CNN).

### Selecci√≥n del Dataset
Dado que se ha trabajado principalmente con datasets de im√°genes en clase, se opt√≥ por utilizar un dataset de im√°genes de carros.

El dataset seleccionado es [Car Images Classification using CNN](https://www.kaggle.com/code/kshitij192/car-images-classification-using-cnn/notebook). de Kaggle. La estructura del dataset es la siguiente:
```
Cars Dataset
‚îú‚îÄ‚îÄ test
‚îÇ   ‚îú‚îÄ‚îÄ Audi (199 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Hyundai Creta (67 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Mahindra Scorpio (75 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Rolls Royce (74 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Swift (102 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Tata Safari (106 im√°genes)
‚îÇ   ‚îî‚îÄ‚îÄ Toyota Innova (190 im√°genes)
|
‚îî‚îÄ‚îÄ train
    ‚îú‚îÄ‚îÄ Audi (814 im√°genes)
    ‚îú‚îÄ‚îÄ Hyundai Creta (271 im√°genes)
    ‚îú‚îÄ‚îÄ Mahindra Scorpio (316 im√°genes)
    ‚îú‚îÄ‚îÄ Rolls Royce (311 im√°genes)
    ‚îú‚îÄ‚îÄ Swift (424 im√°genes)
    ‚îú‚îÄ‚îÄ Tata Safari (441 im√°genes)
    ‚îî‚îÄ‚îÄ Toyota Innova (775 im√°genes)
```

Las im√°genes del dataset tienen una dimensi√≥n de 128x128 p√≠xeles.

### Aumento de Datos
Se est√°n considerando t√©cnicas de aumento de datos para cumplir con el objetivo de alcanzar una proporci√≥n aproximada de 80% para el conjunto de entrenamiento y 20% para el conjunto de prueba (aproximadamente 820 im√°genes de entrenamiento y 200 im√°genes de prueba por clase). El dataset ya viene dividido en entrenamiento y prueba.

#### T√©cnicas de Aumento de Datos

Las t√©cnicas de aumento de datos consideradas, implementadas con la clase ImageDataGenerator de Keras, son:

- **Reescalamiento:** Los valores de los p√≠xeles se dividen por 255 para normalizarlos al rango [0, 1]. Esto es importante para que el modelo pueda procesar los datos de manera m√°s eficiente.

- **Rotaci√≥n aleatoria:** Se rotan las im√°genes hasta 10 grados aleatoriamente. Esto ayuda al modelo a aprender que los objetos pueden aparecer en diferentes orientaciones.

- **Desplazamiento horizontal aleatorio:** Se desplazan las im√°genes horizontalmente hasta 0.1 de su ancho. Esto simula ligeros movimientos del objeto en la imagen.

- **Desplazamiento vertical aleatorio:** Se desplazan las im√°genes verticalmente hasta 0.1 de su altura. Similar al desplazamiento horizontal, esto ayuda al modelo a ser m√°s robusto a los movimientos del objeto.

- **Corte por cizalladura o Shear:** Se aplica una transformaci√≥n de cizalladura con un factor de 0.25. Esto distorsiona la forma de la imagen, simulando una perspectiva diferente.

- **Zoom aleatorio:** Se aplica un zoom a las im√°genes hasta un factor de 0.3. Esto simula objetos que aparecen m√°s cerca o m√°s lejos de la c√°mara.

- **Volteo horizontal aleatorio:** Se voltean las im√°genes horizontalmente de forma aleatoria. Esto ayuda al modelo a aprender que los objetos pueden aparecer en ambas direcciones.

Los par√°metros de aumento de datos se definieron de la siguiente manera:
```
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.25,
    zoom_range=0.3,
    horizontal_flip=True
)
```

### Arquitectura del Modelo
La arquitectura del modelo se basa en una Red Neuronal Convolucional (CNN) con las siguientes capas:

1. **Capa de Convoluci√≥n 2D:** 32 filtros, tama√±o de kernel (3, 3), activaci√≥n ReLU.
2. **Capa de MaxPooling 2D:** Tama√±o de pool (2, 2).
3. **Capa de Convoluci√≥n 2D:** 64 filtros, tama√±o de kernel (3, 3), activaci√≥n ReLU.
4. **Capa de MaxPooling 2D:** Tama√±o de pool (2, 2).
5. **Capa de Dropout:** Tasa de dropout del 0.2. 
6. **Capa de Convoluci√≥n 2D:** 128 filtros, tama√±o de kernel (3, 3), activaci√≥n ReLU.
7. **Capa de MaxPooling 2D:** Tama√±o de pool (2, 2).
8. **Capa de Flatten:** Aplana la salida de la capa anterior.
9. **Capa Densa:** 512 unidades, activaci√≥n ReLU.
10. **Capa de Dropout:** Tasa de dropout del 0.5.
11. **Capa Densa de Salida:** 7 unidades (una por cada clase de carro), activaci√≥n softmax.

#### Capa de Convoluci√≥n
En este modelo, la primera capa de convoluci√≥n utiliza 32 filtros con un tama√±o de kernel de (3, 3) y la funci√≥n de activaci√≥n ReLU. Esta configuraci√≥n permite que el modelo extraiga caracter√≠sticas fundamentales de las im√°genes, como bordes y texturas, desde el inicio del procesamiento.

#### Capa de MaxPooling 2D
A continuaci√≥n, la capa de MaxPooling 2D opera sobre las caracter√≠sticas extra√≠das, utilizando un tama√±o de pooling de (2, 2). As√≠, esta capa reduce la dimensionalidad de los datos generados por la convoluci√≥n y mantiene las caracter√≠sticas m√°s importantes, lo que ayuda a hacer el modelo m√°s eficiente y menos susceptible al sobreajuste.


#### Capa de Dropout
En este caso espec√≠fico, se han incorporado dos capas de Dropout: la primera aplica una tasa de 20% (0.2) justo despu√©s de la capa de convoluci√≥n, y la segunda utiliza una tasa del 50% antes de la capa de salida. Estas capas apagan aleatoriamente un porcentaje de las neuronas en cada paso de entrenamiento. De esta forma, el modelo evita depender demasiado de ciertas neuronas y mejora su capacidad para generalizar a nuevos datos.

#### Capa Dense 
Para finalizar, el modelo utiliza una capa densa con 512 unidades y activaci√≥n ReLU. Esta capa combina las caracter√≠sticas que han sido extra√≠das y procesadas en las etapas anteriores. Dado que es una capa totalmente conectada, cada neurona enlaza con todas las neuronas de la capa anterior, lo que le permite identificar relaciones complejas entre las caracter√≠sticas aprendidas.

En la salida, se emplea otra capa densa, ahora con 7 unidades (una por cada clase de carro) y activaci√≥n softmax. Esta √∫ltima capa convierte la informaci√≥n procesada en probabilidades, indicando la probabilidad de que una imagen corresponda a cada una de las clases posibles en este modelo.

##### Activaci√≥n ReLU
La funci√≥n ReLU (Rectified Linear Unit) toma los valores de entrada y deja pasar √∫nicamente los positivos, mientras que los negativos los convierte en cero. Esto permite que la red neuronal sea m√°s r√°pida de entrenar y ayuda a detectar patrones complejos, ya que a√±ade una ‚Äúno linealidad‚Äù necesaria para el Deep Learning.

##### Activaci√≥n Softmax
La funci√≥n Softmax se utiliza en la capa de salida del modelo. Recibe varios valores num√©ricos y los transforma en probabilidades que suman 1. As√≠, el modelo puede indicar no solo cu√°l clase predice, sino tambi√©n cu√°nta confianza tiene en cada una de las posibles opciones, facilitando la interpretaci√≥n de los resultados en tareas de clasificaci√≥n.



## Compilaci√≥n del Modelo
El modelo se compila utilizando el optimizador Adam, la funci√≥n de p√©rdida categorical_crossentropy y la m√©trica accuracy. Esto permite que el modelo aprenda a clasificar las im√°genes en las diferentes clases de carros.

```python
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

### Papers Revisados

[1] M. Aamir et al, "An Optimized Architecture of Image Classification Using Convolutional Neural Network," International Journal of Image, Graphics and Signal Processing, vol. 10, (10), pp. 30, 2019. Available: https://www.proquest.com/scholarly-journals/optimized-architecture-image-classification-using/docview/2350539949/se-2. DOI: https://doi.org/10.5815/ijigsp.2019.10.05.

[1] A. Manna et al, "Bird Image Classification using Convolutional Neural Network Transfer Learning Architectures," International Journal of Advanced Computer Science and Applications, vol. 14, (3), 2023. Available: https://www.proquest.com/scholarly-journals/bird-image-classification-using-convolutional/docview/2807222514/se-2. DOI: https://doi.org/10.14569/IJACSA.2023.0140397.