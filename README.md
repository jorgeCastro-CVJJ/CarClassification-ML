# Car Classification using a CNN üöó

---

# √çndice

# Objetivo

Desarrollar  un modelo de aprendizaje autom√°tico, Deep Learning, capaz de clasificar imagenes de diferentes marcas de carros utilizados en Redes Neuronales Convolucionales (CNN).

# Selecci√≥n del DataSet

El DataSet seleccionado es [**Car Images Classification using CNN](https://www.kaggle.com/code/kshitij192/car-images-classification-using-cnn/notebook),** de Kaggle. 
La estructura del DataSet es la siguiente:

```jsx
Cars Dataset
‚îú‚îÄ‚îÄ test
‚îÇ   ‚îú‚îÄ‚îÄ Audi (199 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Hyundai Creta (67 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Mahindra Scorpio (75 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Rolls Royce (74 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Swift (102 im√°genes)
‚îÇ   ‚îú‚îÄ‚îÄ Tata Safari (106 im√°genes)
‚îÇ   ‚îî‚îÄ‚îÄ Toyota Innova (190 im√°genes)
|
‚îî‚îÄ‚îÄ train
    ‚îú‚îÄ‚îÄ Audi (814 im√°genes)
    ‚îú‚îÄ‚îÄ Hyundai Creta (271 im√°genes)
    ‚îú‚îÄ‚îÄ Mahindra Scorpio (316 im√°genes)
    ‚îú‚îÄ‚îÄ Rolls Royce (311 im√°genes)
    ‚îú‚îÄ‚îÄ Swift (424 im√°genes)
    ‚îú‚îÄ‚îÄ Tata Safari (441 im√°genes)
    ‚îî‚îÄ‚îÄ Toyota Innova (775 im√°genes)
```

Las im√°genes del DataSet tienen una dimensi√≥n de **128x128 pix√©les.**

## Divisi√≥n del DataSet

El dataset se dividi√≥ en dos variantes: el Dataset Base y el Dataset con Data Generation. Para cada variante, se realiz√≥ la siguiente distribuci√≥n para asegurar un entrenamiento efectivo y una evaluaci√≥n confiable del modelo:

| Conjunto | Cantidad de Im√°genes por Clase | Porcentaje Aproximado |
| --- | --- | --- |
| Entrenamiento (Train) | 720 | 70% |
| Validaci√≥n (Validation) | 100 | 10% |
| Prueba (Test) | 200 | 20% |

Para visualizar mejor la estructura y el flujo de ambos datasets, se presenta el siguiente diagrama:

```mermaid
graph LR;
    A["Dataset Original"] --> B["Divisi√≥n en Datasets"];
    B --> C["Dataset Base"];
    B --> D["Dataset con Data Generation"];
    C --> E["Train Base <br>(desbalanceado)"];
    C --> F["Validaci√≥n Base<br> (100/clase)"];
    C --> G["Test Base <br>(desbalanceado)"];
    D --> H["Train Aumentado <br>(720/clase)"];
    D --> I["Validaci√≥n Aumentada <br>(100/clase)"];
    D --> J["Test Aumentado <br>(200/clase)"];
    
    style A fill:#d4f1f4
    style B fill:#e8f6f7
    style C fill:#95dae8
    style D fill:#95dae8
    style E fill:#189ab4
    style H fill:#189ab4
    style F fill:#189ab4
    style I fill:#189ab4
    style G fill:#189ab4
    style J fill:#189ab4

```

Para manejar el desbalance inicial en el dataset, donde algunas clases ten√≠an significativamente m√°s muestras que otras, se crearon dos variantes: un Dataset Base y otro con t√©cnicas de aumento de datos (Data Generation). Se equilibraron las clases a aproximadamente 820 im√°genes por clase, separando 100 im√°genes para validaci√≥n y dejando 720 para entrenamiento efectivo.

## T√©cnicas de Aumento de Datos y Preprocesamiento

Para mejorar la robustez y capacidad de generalizaci√≥n del modelo, se implementaron diversas t√©cnicas de aumento de datos. Estas transformaciones permiten crear variaciones sint√©ticas de las im√°genes originales, expandiendo efectivamente el conjunto de datos de entrenamiento.

### Transformaciones Implementadas

<aside>
**Normalizaci√≥n y Preprocesamiento**

- **Reescalamiento:** Normalizaci√≥n de p√≠xeles al rango [0, 1], facilitando el procesamiento y convergencia del modelo al estandarizar los valores de entrada.
</aside>

<aside>
**Transformaciones Geom√©tricas**

- **Rotaci√≥n (10¬∞):** Gira las im√°genes aleatoriamente, ayudando al modelo a reconocer objetos en diferentes √°ngulos.
- **Desplazamiento (10%):** Mueve la imagen horizontal y verticalmente, simulando objetos en diferentes posiciones dentro del marco.
- **Cizalladura o Shear (0.25):** Distorsiona la imagen para simular cambios en la perspectiva de visualizaci√≥n.
- **Zoom (30%):** Acerca o aleja la imagen, permitiendo que el modelo aprenda a reconocer objetos a diferentes escalas.
- **Volteo horizontal:** Invierte la imagen horizontalmente, √∫til para reconocer objetos independientemente de su orientaci√≥n.
</aside>

### Implementaci√≥n

```python
train_datagen = ImageDataGenerator(
    rescale=1./255,          # Normalizaci√≥n
    rotation_range=10,       # Rotaci√≥n aleatoria
    width_shift_range=0.1,   # Desplazamiento horizontal
    height_shift_range=0.1,  # Desplazamiento vertical
    shear_range=0.25,       # Cizalladura o Shear
    zoom_range=0.3,         # Zoom aleatorio
    horizontal_flip=True     # Volteo horizontal
)
```

Estas transformaciones se aplican de manera aleatoria durante el entrenamiento, lo que ayuda a:

- Prevenir el sobreajuste (overfitting)
- Mejorar la generalizaci√≥n del modelo
- Aumentar la diversidad del conjunto de datos
- Hacer el modelo m√°s robusto ante variaciones en las im√°genes de entrada

# M√©tricas

Para evaluar el rendimiento del modelo de clasificaci√≥n, se utilizan las siguientes m√©tricas:

| M√©trica | Descripci√≥n | Importancia |
| --- | --- | --- |
| **Accuracy** | Proporci√≥n de predicciones correctas sobre el total de predicciones | √ötil para tener una visi√≥n general del rendimiento, pero puede ser enga√±osa en datasets desbalanceados |
| **Precision** | De todas las predicciones positivas, cu√°ntas fueron correctas | Importante cuando queremos minimizar falsos positivos (alta confiabilidad en predicciones positivas) |
| **Recall** | De todos los casos realmente positivos, cu√°ntos fueron identificados correctamente | Crucial cuando queremos minimizar falsos negativos (no perder casos positivos reales) |
| **F1-Score** | Media arm√≥nica entre precisi√≥n y recall | Proporciona un balance entre precisi√≥n y recall, especialmente √∫til en datasets desbalanceados |

Estas m√©tricas son particularmente relevantes para nuestro caso de clasificaci√≥n de veh√≠culos porque:

- Tenemos un dataset desbalanceado (diferentes cantidades de im√°genes por clase)
- Necesitamos evaluar el rendimiento por clase individual
- Es importante tanto identificar correctamente los veh√≠culos (precision) como no perder clasificaciones correctas (recall)

# Primer Modelo

---

## Construcci√≥n del Primer Modelo

### Arquitectura CNN B√°sica

Una Red Neuronal Convolucional (CNN) b√°sica t√≠picamente consiste en una serie de capas organizadas secuencialmente. Cada capa cumple una funci√≥n espec√≠fica en el proceso de extracci√≥n y procesamiento de caracter√≠sticas de las im√°genes.

![Figura 2. Modelo b√°sico de una Red Neuronal Convolucional.](readme%20images/image.png)

Figura 2. Modelo b√°sico de una Red Neuronal Convolucional.

<aside>

Los componentes principales de una CNN b√°sica incluyen:

- **Capas Convolucionales:** Extraen caracter√≠sticas de las im√°genes mediante filtros que detectan patrones espec√≠ficos.
- **Capas de Pooling:** Reducen la dimensionalidad de los mapas de caracter√≠sticas mientras mantienen la informaci√≥n m√°s relevante.
- **Capa de Aplanamiento:** Convierte los mapas de caracter√≠sticas en un vector unidimensional.
- **Capas Densas:** Procesan las caracter√≠sticas extra√≠das para realizar la clasificaci√≥n final.
</aside>

### Arquitectura Implementada

Para este proyecto, se utiliz√≥ como punto de partida la arquitectura propuesta en el notebook de Kaggle "Car Images Classification using CNN". Esta arquitectura sirve como base para nuestro primer modelo y nos permitir√° establecer un rendimiento inicial de referencia.

```python
# Arquitectura del modelo base
model_kaggle = models.Sequential([
    # Primera capa convolucional
    Conv2D(32, (3, 3), input_shape=(IMG_SIZE, IMG_SIZE, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    
    # Segunda capa convolucional
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    
    # Aplanamiento y capas densas
    Flatten(),
    Dense(96, activation='relu'),
    Dropout(0.40),
    Dense(32, activation='relu'),
    Dense(7, activation='softmax')  # Capa de salida para 7 clases
])
```

La arquitectura del primer modelo consiste en:

- **Capas Convolucionales:** Dos bloques de convoluci√≥n, cada uno con 32 filtros y kernel de 3x3, usando activaci√≥n ReLU
- **Capas de Pooling:** MaxPooling2D despu√©s de cada capa convolucional para reducir dimensionalidad
- **Capas Densas:**
    - Primera capa densa con 96 unidades
    - Capa de dropout (40%) para prevenir overfitting
    - Segunda capa densa con 32 unidades
    - Capa de salida con 7 unidades (una por clase) y activaci√≥n softmax

### Funciones de Activaci√≥n

### ReLU (Rectified Linear Unit)

ReLU es una funci√≥n de activaci√≥n no lineal que se utiliza com√∫nmente en las capas convolucionales y densas. Su funcionamiento es simple pero efectivo:

- Para valores de entrada negativos, la salida es 0
- Para valores de entrada positivos, la salida es igual al valor de entrada

Matem√°ticamente se expresa como: f(x) = max(0,x)

Ventajas principales de ReLU:

- Reduce el problema del desvanecimiento del gradiente
- Computacionalmente eficiente
- Permite un entrenamiento m√°s r√°pido de redes profundas

![Figura 3. Funci√≥n de Activaci√≥n ReLu en gr√°fica.](readme%20images/image%201.png)

Figura 3. Funci√≥n de Activaci√≥n ReLu en gr√°fica.

### Softmax

Softmax es una funci√≥n de activaci√≥n utilizada en la capa de salida para problemas de clasificaci√≥n multiclase. Sus caracter√≠sticas principales son:

- Convierte las salidas en probabilidades que suman 1
- Asigna probabilidades m√°s altas a los valores m√°s grandes de entrada
- Permite interpretar la confianza del modelo en cada predicci√≥n

![Figura 4. Funci√≥n de Activaci√≥n SoftMax en una gr√°fica.](readme%20images/image%202.png)

Figura 4. Funci√≥n de Activaci√≥n SoftMax en una gr√°fica.

## Compilaci√≥n del Primer Modelo

Para la compilaci√≥n del modelo se utilizaron los siguientes par√°metros:

- **Optimizer:** Adam - Un optimizador adaptativo que ajusta autom√°ticamente las tasas de aprendizaje durante el entrenamiento.
- **Loss Function:** Categorical Crossentropy - Funci√≥n de p√©rdida adecuada para problemas de clasificaci√≥n multiclase.
- **Metric:** Accuracy - Para medir la proporci√≥n de predicciones correctas durante el entrenamiento.

```python
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
```

## An√°lisis de Resultados

Bas√°ndonos en los resultados del segundo modelo, podemos realizar el siguiente an√°lisis:

### Rendimiento General

El modelo alcanz√≥ una precisi√≥n global (accuracy) del 69%, la cual se toma como la linea base para la mejora del modelo en la segunda iteraci√≥n y al momdento de balancear el DataSet.

### An√°lisis por Clase

- **Mejor desempe√±o:** Toyota Innova (F1-Score: 0.78) indicando una mejor capacidad de identificaci√≥n de caracter√≠sticas. Al igual Audi (F1-Score: 0.73) y Tata Safari (F1-Score: 0.77) alzcanzaron un buen desempe√±o.
- **Balance en m√©tricas:** Existe un desbalance entre las clases, principalmente por la cantidad de imagenes en el dataset para cada clase. Sabemos que Audi y Toyota eran las que tienen mayor cantidad de imagenes. Por lo tanto hay un Bias hacia estas dos clases.

### An√°lisis de Gr√°ficas

- Tanto la gr√°fica de Loss como de Accuracy nos muestran un Overfitting por parte del modelo. Como se mencion√≥ anteriormente, el desbalance en la cantidad de fotos para cada clase puede ser un indicador clave de que el modelo confunda Rolls Royce, Hyundai o Mahindra Scorpio con Audi o Toyotas debido a que no ha visto m√°s de estas dos √∫ltimas clases mencionadas.

| Clase | Precisi√≥n | Recall | F1-Score | Support |
| --- | --- | --- | --- | --- |
| Audi | 0.61 | 0.91 | 0.73 | 199 |
| Hyundai Creta | 0.70 | 0.24 | 0.36 | 67 |
| Mahindra Scorpio | 0.73 | 0.43 | 0.54 | 75 |
| Rolls Royce | 0.57 | 0.27 | 0.37 | 74 |
| Swift | 0.72 | 0.67 | 0.69 | 102 |
| Tata Safari | 0.77 | 0.77 | 0.77 | 106 |
| Toyota Innova | 0.73 | 0.83 | 0.78 | 190 |
| Accuracy |  |  | **0.69** | **813** |
| Macro Avg | 0.69 | 0.59 | 0.61 | 813 |
| Weighted Avg | 0.69 | 0.69 | 0.66 | 813 |

`Test Accuracy: 0.6851`

![Figura 5. Matriz de Confusi√≥n del Modelo Base.](readme%20images/image%203.png)

Figura 5. Matriz de Confusi√≥n del Modelo Base.

![FIgura 6. Gr√°fica de Accuracy vs. Epocas del Modelo Base. Se observa un overfitting por parte del modelo.](readme%20images/image%204.png)

FIgura 6. Gr√°fica de Accuracy vs. Epocas del Modelo Base. Se observa un overfitting por parte del modelo.

![FIgura 7. Gr√°fica de Loss vs. Epocas del Modelo Base.](readme%20images/image%205.png)

FIgura 7. Gr√°fica de Loss vs. Epocas del Modelo Base.

## Conclusiones iniciales

El an√°lisis del modelo base revela importantes hallazgos sobre su rendimiento. En primer lugar, se observa un claro problema de sobreajuste (overfitting) durante el entrenamiento, evidenciado por la divergencia entre el rendimiento en datos de entrenamiento y validaci√≥n.

La causa principal de este comportamiento radica en el desbalance del conjunto de datos. Las clases mayoritarias como Audi y Toyota Innova, con aproximadamente 200 im√°genes cada una, dominan el aprendizaje del modelo. Esto se refleja en sus altos F1-Scores (0.73 y 0.78 respectivamente), mientras que clases minoritarias como Rolls Royce, con menos muestras, obtienen m√©tricas significativamente inferiores (F1-Score de 0.37).

Este desbalance tiene un impacto directo en la capacidad del modelo para generalizar, resultando en un sesgo hacia las clases con mayor representaci√≥n. Los resultados enfatizan la necesidad cr√≠tica de implementar t√©cnicas de balanceo de datos para mejorar el rendimiento global del modelo y asegurar una clasificaci√≥n m√°s equitativa entre todas las categor√≠as de veh√≠culos.

# Segundo Modelo

Para el segundo modelo la arquitectura que se usa proviene de la publicaci√≥n *‚ÄúAn Optimized Architecture of Image Classification Using Convolutional Neural Network‚Äù* . Propone que con esta configuraci√≥n de capas se utiliza menos memoria al momento de entrenar el modelo sin sacrificar la eficiencia del mismo en la clasificaci√≥n de imagenes. 

# Arquitectura Optimizada

La arquitectura optimizada del segundo modelo presenta las siguientes caracter√≠sticas principales:

- **Capas Convolucionales m√°s profundas:**
    - Primera capa: 16 filtros (3x3) con activaci√≥n ReLU
    - Segunda capa: 32 filtros (3x3) con activaci√≥n ReLU
    - Tercera capa: 64 filtros (3x3) con activaci√≥n ReLU
    - Cuarta capa: 128 filtros (3x3) con activaci√≥n ReLU
- **Regularizaci√≥n mejorada:**
    - Restricci√≥n de norma m√°xima (max_norm) en todas las capas convolucionales
    - Dos capas de Dropout: una al 20% despu√©s de la tercera capa convolucional y otra al 50% antes de la capa densa final
- **Capa densa ampliada:** Una capa densa de 512 unidades antes de la capa de salida, proporcionando mayor capacidad de aprendizaje
- **MaxPooling:** Capas de MaxPooling (2x2) despu√©s de cada capa convolucional para reducir dimensionalidad

Esta arquitectura m√°s profunda y regularizada busca mejorar la capacidad de extracci√≥n de caracter√≠sticas y prevenir el sobreajuste observado en el primer modelo.

```python
img_shape = (IMG_SIZE, IMG_SIZE, 3)
model_optimized = models.Sequential()

model_optimized.add(Conv2D(16,(3, 3),activation="relu", kernel_constraint=max_norm(3), input_shape=img_shape))
model_optimized.add(MaxPooling2D((2, 2)))

model_optimized.add(Conv2D(32, (3, 3),activation="relu", kernel_constraint=max_norm(3), input_shape=img_shape))
model_optimized.add(MaxPooling2D((2, 2)))

model_optimized.add(Conv2D(64, (3, 3),activation="relu", kernel_constraint=max_norm(3)))
model_optimized.add(MaxPooling2D((2, 2)))

model_optimized.add(Dropout(0.2))

model_optimized.add(Conv2D(128, (3, 3), activation="relu", kernel_constraint=max_norm(3)))
model_optimized.add(MaxPooling2D((2, 2)))

model_optimized.add(Flatten())

model_optimized.add(Dropout(0.5))
model_optimized.add(Dense(512, activation='relu'))
model_optimized.add(Dense(7, activation='softmax'))

model_optimized.summary()
```

En la parte de compilamiento del modelo al igual que la evaluaci√≥n se mantiene sin cambios.

## An√°lisis de Resultados

| Class | Precision | Recall | F1-Score | Support |
| --- | --- | --- | --- | --- |
| Audi | 0.78 | 0.91 | 0.84 | 199 |
| Hyundai Creta | 0.68 | 0.76 | 0.72 | 67 |
| Mahindra Scorpio | 0.81 | 0.89 | 0.85 | 75 |
| Rolls Royce | 0.77 | 0.58 | 0.66 | 74 |
| Swift | 0.90 | 0.80 | 0.85 | 102 |
| Tata Safari | 0.92 | 0.79 | 0.85 | 106 |
| Toyota Innova | 0.94 | 0.91 | 0.92 | 190 |
| **Accuracy** |  |  | 0.84 | 813 |
| **Macro Avg** | 0.83 | 0.81 | 0.81 | 813 |
| **Weighted Avg** | 0.84 | 0.84 | 0.84 | 813 |

`Test Acurracy: 0.8388`

![Figura 8. Matr√≠z de Confusi√≥n del Modelo Optimizado](readme%20images/image%206.png)

Figura 8. Matr√≠z de Confusi√≥n del Modelo Optimizado

![Figura 9. Gr√°fica de Accuracy vs. Epocas del Modelo Optimizado.](readme%20images/image%207.png)

Figura 9. Gr√°fica de Accuracy vs. Epocas del Modelo Optimizado.

![Figura 10. Gr√°fica de Loss vs. Epocas del Modelo Optimizado.](readme%20images/image%208.png)

Figura 10. Gr√°fica de Loss vs. Epocas del Modelo Optimizado.

## Conclusiones del Segundo Modelo

El an√°lisis del segundo modelo revela mejoras significativas en el rendimiento general de la clasificaci√≥n. La comparaci√≥n de m√©tricas entre el modelo base y el optimizado muestra un incremento sustancial en el F1-Score promedio, pasando de 0.61 a 0.81, lo que representa una mejora del 33% en la capacidad de clasificaci√≥n.

Las clases que inicialmente presentaban un rendimiento inferior mostraron mejoras notables. Por ejemplo, Hyundai Creta increment√≥ su F1-Score de 0.36 a 0.72, mientras que Rolls Royce mejor√≥ de 0.37 a 0.66. La precisi√≥n general del modelo tambi√©n experiment√≥ un aumento considerable, elev√°ndose de 0.69 a 0.84.

Sin embargo, como se evidencia en las Figuras 9 y 10, que muestran las gr√°ficas de precisi√≥n y p√©rdida respectivamente, persiste un ligero sobreajuste, aunque menos pronunciado que en el modelo base. Esto indica que, a pesar de las mejoras significativas en la arquitectura optimizada, existe potencial para futuras optimizaciones en t√©rminos de regularizaci√≥n y capacidad de generalizaci√≥n.

# M√©tricas con el DataSet Aumentado

---

Tras realizar el an√°lisis inicial con el Dataset Base (desbalanceado), se procedi√≥ a implementar t√©cnicas de aumentaci√≥n de datos para crear un Dataset Balanceado. Este proceso tuvo como objetivo principal equilibrar la representaci√≥n de cada clase de veh√≠culo, estableciendo 720 im√°genes por categor√≠a en el conjunto de entrenamiento (train) y 200 im√°genes por categor√≠a en el conjunto de prueba (test).

La aumentaci√≥n de datos se realiz√≥ mediante las mismas transformaciones mencionadas al inicio del reporte, preservando las caracter√≠sticas esenciales de los veh√≠culos mientras se introducen variaciones controladas.

A continuaci√≥n, se presentan los resultados obtenidos al entrenar tanto el Modelo Base como el Modelo Optimizado utilizando este Dataset Balanceado. Este an√°lisis comparativo nos permitir√° evaluar el impacto de la aumentaci√≥n de datos en la reducci√≥n del sesgo y la mejora en la capacidad de generalizaci√≥n de ambos modelos.

## Resultados Primer Modelo (Augmented)

| Clase | Precision | Recall | F1-Score | Support |
| --- | --- | --- | --- | --- |
| Audi | 0.50 | 0.90 | 0.65 | 200 |
| Hyundai Creta | 0.80 | 0.47 | 0.59 | 200 |
| Mahindra Scorpio | 0.68 | 0.56 | 0.62 | 200 |
| Rolls Royce | 0.60 | 0.47 | 0.53 | 200 |
| Swift | 0.75 | 0.58 | 0.66 | 200 |
| Tata Safari | 0.78 | 0.73 | 0.76 | 200 |
| Toyota Innova | 0.60 | 0.80 | 0.68 | 200 |
| Accuracy |  |  | 0.64 | 1400 |
| Macro Avg | 0.67 | 0.64 | 0.64 | 1400 |
| Weighted Avg | 0.67 | 0.64 | 0.64 | 1400 |

`Test Accuracy: 0.6435`

![Figura 11. Matr√≠z de Confusi√≥n del Modelo Base con DataSet Balanceado (Augmented).](readme%20images/image%209.png)

Figura 11. Matr√≠z de Confusi√≥n del Modelo Base con DataSet Balanceado (Augmented).

![Figura 12. Gr√°fica de Accuracy vs. Epocas del Modelo Base con DataSet Balanceado (Augmented).](readme%20images/image%2010.png)

Figura 12. Gr√°fica de Accuracy vs. Epocas del Modelo Base con DataSet Balanceado (Augmented).

![Figura 13. Gr√°fica de Loss vs. Epocas del Modelo Base con DataSet Balanceado (Augmented).](readme%20images/image%2011.png)

Figura 13. Gr√°fica de Loss vs. Epocas del Modelo Base con DataSet Balanceado (Augmented).

### An√°lisis del Primer Modelo (Augmented)

La evaluaci√≥n del primer modelo con el dataset aumentado revela transformaciones interesantes en su desempe√±o. A primera vista, la precisi√≥n general alcanz√≥ un 64.35%, representando una ligera reducci√≥n respecto al modelo base original que logr√≥ un 69%.

- **Distribuci√≥n equilibrada:** Un cambio notable es la nueva distribuci√≥n uniforme del dataset, que ahora cuenta con 200 im√°genes por categor√≠a, eliminando el sesgo presente en la versi√≥n anterior.
- **Rendimiento por marca:** El comportamiento espec√≠fico por fabricante muestra patrones interesantes:
    - Los veh√≠culos Audi destacan con un excelente recall de 0.90, aunque su precisi√≥n se situ√≥ en 0.50
    - Hyundai Creta experiment√≥ una notable mejora en precisi√≥n, alcanzando 0.80
    - La marca Tata Safari mantiene su solidez con un F1-Score de 0.76
- **Evoluci√≥n del aprendizaje:** Las visualizaciones de p√©rdida y precisi√≥n evidencian un mejor control del sobreajuste, sugiriendo que la aumentaci√≥n de datos fortaleci√≥ la capacidad de generalizaci√≥n del modelo.

En conjunto, estos hallazgos sugieren que la estrategia de aumentaci√≥n de datos, si bien introdujo mayor complejidad en la tarea de clasificaci√≥n, contribuy√≥ a crear un modelo m√°s robusto y equilibrado, aunque con un peque√±o sacrificio en la precisi√≥n global.

## Resultado Segundo Modelo (Augmented)

| Class | Precision | Recall | F1-Score | Support |
| --- | --- | --- | --- | --- |
| Audi | 0.67 | 0.91 | 0.77 | 200 |
| Hyundai Creta | 0.93 | 0.68 | 0.78 | 200 |
| Mahindra Scorpio | 0.84 | 0.84 | 0.84 | 200 |
| Rolls Royce | 0.81 | 0.62 | 0.71 | 200 |
| Swift | 0.89 | 0.85 | 0.87 | 200 |
| Tata Safari | 0.87 | 0.91 | 0.89 | 200 |
| Toyota Innova | 0.79 | 0.93 | 0.85 | 200 |
| Accuracy |  |  | 0.82 | 1400 |
| Macro Avg | 0.83 | 0.82 | 0.82 | 1400 |
| Weighted Avg | 0.83 | 0.82 | 0.82 | 1400 |

`Test Accuracy: 0.8178`

![Figura 14. Matr√≠z de Confusi√≥n Modelo Optimizado (Augmented)](readme%20images/image%2012.png)

Figura 14. Matr√≠z de Confusi√≥n Modelo Optimizado (Augmented)

![Figura 15. Gr√°fica Accuracy vs. Epocas Modelo Optimizado (Augmented)](readme%20images/image%2013.png)

Figura 15. Gr√°fica Accuracy vs. Epocas Modelo Optimizado (Augmented)

![Figura 16. Gr√°fica Loss vs. Epocas Modelo Optimizado (Augmented)](readme%20images/image%2014.png)

Figura 16. Gr√°fica Loss vs. Epocas Modelo Optimizado (Augmented)

### An√°lisis del Segundo Modelo (Augmented)

El an√°lisis del segundo modelo con el dataset aumentado muestra resultados notablemente positivos, alcanzando una precisi√≥n general del 81.78%, lo cual representa una mejora significativa respecto al primer modelo aumentado (64.35%). Este rendimiento se mantiene cercano al modelo optimizado original (83.88%), demostrando la robustez de la arquitectura mejorada incluso con un conjunto de datos m√°s desafiante y equilibrado.

- **Mejoras espec√≠ficas por marca:**
    - Tata Safari mantiene un excelente desempe√±o con un F1-Score de 0.89
    - Swift muestra un rendimiento sobresaliente con un F1-Score de 0.87
    - Mahindra Scorpio y Toyota Innova presentan m√©tricas muy equilibradas con F1-Scores de 0.84 y 0.85 respectivamente
- **Comparaci√≥n con el modelo optimizado original:**
    - La precisi√≥n general se mantiene similar (81.78% vs 83.88%)
    - Las m√©tricas por clase muestran mayor consistencia y equilibrio
    - El modelo demuestra mejor capacidad de generalizaci√≥n con el dataset balanceado

Las gr√°ficas de entrenamiento muestran un comportamiento m√°s estable y controlado, con menor evidencia de sobreajuste en comparaci√≥n con las versiones anteriores. Esto sugiere que la combinaci√≥n de la arquitectura optimizada con el dataset aumentado ha resultado en un modelo m√°s robusto y confiable para la clasificaci√≥n de veh√≠culos.

# Conclusiones Finales

El an√°lisis exhaustivo de los modelos implementados ha revelado conclusiones significativas que demuestran la evoluci√≥n y mejora en el proceso de clasificaci√≥n de veh√≠culos:

- **Optimizaci√≥n arquitect√≥nica exitosa:** La reestructuraci√≥n del modelo result√≥ determinante, evidenciada por un incremento sustancial en la precisi√≥n, pasando del 64.35% al 81.78% en el dataset aumentado. Este avance subraya la importancia cr√≠tica de una arquitectura cuidadosamente optimizada.
- **Beneficios del balance de datos:** La implementaci√≥n del dataset balanceado, aunque implic√≥ una modesta disminuci√≥n en la precisi√≥n global, gener√≥ beneficios sustanciales:
    - Distribuci√≥n equitativa entre clases (200 im√°genes por categor√≠a)
    - Minimizaci√≥n significativa del sesgo clasificatorio
    - Incremento notable en la capacidad de generalizaci√≥n
- **Logros m√©tricos sobresalientes:**
    - Mejora consistente del F1-Score en todas las categor√≠as
    - Rendimiento excepcional en Tata Safari (0.89), Swift (0.87) y Toyota Innova (0.85)
    - Armonizaci√≥n notable entre precisi√≥n y recall en el espectro completo de categor√≠as

Para potenciar a√∫n m√°s el rendimiento del modelo, se proponen las siguientes recomendaciones estrat√©gicas:

- **Optimizaci√≥n mediante ponderaci√≥n de clases:** Incorporar class weights para gestionar eficientemente los desequilibrios residuales en categor√≠as subrepresentadas.
- **T√©cnicas sofisticadas de aumentaci√≥n:** Integrar metodolog√≠as avanzadas como:
    - Mixup: Fusi√≥n estrat√©gica de im√°genes para generar muestras enriquecidas
    - CutMix: T√©cnicas de segmentaci√≥n y combinaci√≥n selectiva de elementos visuales
    - Pol√≠ticas de aumentaci√≥n din√°micamente adaptativas
- **Innovaci√≥n arquitect√≥nica:**
    - Implementaci√≥n de modelos pre-entrenados de √∫ltima generaci√≥n
    - Desarrollo de sistemas de ensemble learning robustos
    - Exploraci√≥n de arquitecturas especializadas en reconocimiento vehicular
- **Refinamiento de hiperpar√°metros:** Aplicaci√≥n de metodolog√≠as avanzadas como Optimizaci√≥n Bayesiana o b√∫squeda en cuadr√≠cula para maximizar la eficiencia param√©trica.

La implementaci√≥n de estas mejoras propuestas tiene el potencial de elevar significativamente el desempe√±o del modelo actual, particularmente en escenarios de alta complejidad o requisitos espec√≠ficos de clasificaci√≥n.

# Referencias

[1] M. Aamir et al, "An Optimized Architecture of Image Classification Using Convolutional Neural Network," International Journal of Image, Graphics and Signal Processing, vol. 10, (10), pp. 30, 2019. Available: [https://www.proquest.com/scholarly-journals/optimized-architecture-image-classification-using/docview/2350539949/se-2](https://www.proquest.com/scholarly-journals/optimized-architecture-image-classification-using/docview/2350539949/se-2). DOI: [https://doi.org/10.5815/ijigsp.2019.10.05](https://doi.org/10.5815/ijigsp.2019.10.05).

[2] A. Manna et al, "Bird Image Classification using Convolutional Neural Network Transfer Learning Architectures," International Journal of Advanced Computer Science and Applications, vol. 14, (3), 2023. Available: [https://www.proquest.com/scholarly-journals/bird-image-classification-using-convolutional/docview/2807222514/se-2](https://www.proquest.com/scholarly-journals/bird-image-classification-using-convolutional/docview/2807222514/se-2). DOI: [https://doi.org/10.14569/IJACSA.2023.0140397](https://doi.org/10.14569/IJACSA.2023.0140397).

[3] K. Kshitij, ‚ÄúCar Image Classification using CNN‚Äù. Kaggle. 2022 Available: [Car Images classification using CNN](https://www.kaggle.com/code/kshitij192/car-images-classification-using-cnn/notebook).
